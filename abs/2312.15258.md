### Human101: Training 100+FPS Human Gaussians in 100s from 1 View

Reconstructing the human body from single-view videos plays a pivotal role in the virtual reality domain. One prevalent application scenario necessitates the rapid reconstruction of high-fidelity 3D digital humans while simultaneously ensuring real-time rendering and interaction. Existing methods often struggle to fulfill both requirements. In this paper, we introduce Human101, a novel framework adept at producing high-fidelity dynamic 3D human reconstructions from 1-view videos by training 3D Gaussians in 100 seconds and rendering in 100+ FPS. Our method leverages the strengths of 3D Gaussian Splatting, which provides an explicit and efficient representation of 3D humans. Standing apart from prior NeRF-based pipelines, Human101 ingeniously applies a Human-centric Forward Gaussian Animation method to deform the parameters of 3D Gaussians, thereby enhancing rendering speed (i.e., rendering 1024-resolution images at an impressive 60+ FPS and rendering 512-resolution images at 100+ FPS). Experimental results indicate that our approach substantially eclipses current methods, clocking up to a 10 times surge in frames per second and delivering comparable or superior rendering quality.

在虚拟现实领域，从单视图视频重建人体扮演着关键角色。一种流行的应用场景需要快速重建高保真度的3D数字人类，同时确保实时渲染和交互。现有方法通常难以满足这两个要求。在本文中，我们介绍了Human101，这是一个新颖的框架，能够通过在100秒内训练3D高斯并以100+ FPS的速度渲染，从1视图视频中生成高保真度的动态3D人类重建。我们的方法利用了3D高斯涂抹的优势，为3D人类提供了一种显式且高效的表征。与以往基于NeRF的管道不同，Human101巧妙地应用了以人为中心的前向高斯动画方法来变形3D高斯的参数，从而提高了渲染速度（即以60+ FPS渲染1024分辨率的图像，以100+ FPS渲染512分辨率的图像）。实验结果表明，我们的方法大幅超越了当前的方法，帧数每秒提高了高达10倍，并提供了可比拟或更优越的渲染质量。
