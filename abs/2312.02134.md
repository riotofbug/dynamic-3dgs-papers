### GaussianAvatar: Towards Realistic Human Avatar Modeling from a Single Video via Animatable 3D Gaussians

We present GaussianAvatar, an efficient approach to creating realistic human avatars with dynamic 3D appearances from a single video. We start by introducing animatable 3D Gaussians to explicitly represent humans in various poses and clothing styles. Such an explicit and animatable representation can fuse 3D appearances more efficiently and consistently from 2D observations. Our representation is further augmented with dynamic properties to support pose-dependent appearance modeling, where a dynamic appearance network along with an optimizable feature tensor is designed to learn the motion-to-appearance mapping. Moreover, by leveraging the differentiable motion condition, our method enables a joint optimization of motions and appearances during avatar modeling, which helps to tackle the long-standing issue of inaccurate motion estimation in monocular settings. The efficacy of GaussianAvatar is validated on both the public dataset and our collected dataset, demonstrating its superior performances in terms of appearance quality and rendering efficiency.

我们介绍了 GaussianAvatar，这是一种从单个视频创建逼真的动态三维人类形象的高效方法。我们首先引入可动画的三维高斯模型来明确表示各种姿势和服装风格的人类。这种明确且可动画的表示可以更有效、更一致地从二维观测中融合三维外观。我们的表示进一步增加了动态属性，以支持依赖于姿势的外观建模，其中设计了一个动态外观网络和一个可优化的特征张量，用于学习运动到外观的映射。此外，通过利用可微分的运动条件，我们的方法可以在形象建模过程中对运动和外观进行联合优化，这有助于解决单眼设置中运动估计不准确的长期问题。在公共数据集和我们收集的数据集上验证了 GaussianAvatar 的有效性，其在外观质量和渲染效率方面表现出色。
