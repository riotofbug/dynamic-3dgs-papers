### MonoGaussianAvatar: Monocular Gaussian Point-based Head Avatar

The ability to animate photo-realistic head avatars reconstructed from monocular portrait video sequences represents a crucial step in bridging the gap between the virtual and real worlds. Recent advancements in head avatar techniques, including explicit 3D morphable meshes (3DMM), point clouds, and neural implicit representation have been exploited for this ongoing research. However, 3DMM-based methods are constrained by their fixed topologies, point-based approaches suffer from a heavy training burden due to the extensive quantity of points involved, and the last ones suffer from limitations in deformation flexibility and rendering efficiency. In response to these challenges, we propose MonoGaussianAvatar (Monocular Gaussian Point-based Head Avatar), a novel approach that harnesses 3D Gaussian point representation coupled with a Gaussian deformation field to learn explicit head avatars from monocular portrait videos. We define our head avatars with Gaussian points characterized by adaptable shapes, enabling flexible topology. These points exhibit movement with a Gaussian deformation field in alignment with the target pose and expression of a person, facilitating efficient deformation. Additionally, the Gaussian points have controllable shape, size, color, and opacity combined with Gaussian splatting, allowing for efficient training and rendering. Experiments demonstrate the superior performance of our method, which achieves state-of-the-art results among previous methods.

在单目人像视频序列中重建逼真的头部形象的能力，代表了连接虚拟世界与现实世界之间的关键一步。最近在头部形象技术方面的进展，包括显式的三维可变形网格（3DMM）、点云和神经隐式表示，已被用于这一持续的研究。然而，基于3DMM的方法受限于其固定的拓扑结构，基于点的方法由于涉及的点数量庞大而承受着繁重的训练负担，最后一种方法在变形灵活性和渲染效率上存在局限性。为了应对这些挑战，我们提出了 MonoGaussianAvatar（单目高斯点基头部形象），这是一种新颖的方法，它利用三维高斯点表示与高斯变形场结合，从单目人像视频中学习显式头部形象。我们用具有可调整形状的高斯点定义头部形象，从而实现灵活的拓扑结构。这些点随着目标姿势和人的表情，通过高斯变形场展示运动，从而实现高效的变形。此外，高斯点具有可控的形状、大小、颜色和不透明度，结合高斯分散，允许高效的训练和渲染。实验展示了我们方法的卓越性能，它在先前方法中实现了最先进的结果。
