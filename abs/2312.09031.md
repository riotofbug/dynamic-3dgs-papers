### iComMa: Inverting 3D Gaussians Splatting for Camera Pose Estimation via Comparing and Matching

We present a method named iComMa to address the 6D pose estimation problem in computer vision. The conventional pose estimation methods typically rely on the target's CAD model or necessitate specific network training tailored to particular object classes. Some existing methods address mesh-free 6D pose estimation by employing the inversion of a Neural Radiance Field (NeRF), aiming to overcome the aforementioned constraints. However, it still suffers from adverse initializations. By contrast, we model the pose estimation as the problem of inverting the 3D Gaussian Splatting (3DGS) with both the comparing and matching loss. In detail, a render-and-compare strategy is adopted for the precise estimation of poses. Additionally, a matching module is designed to enhance the model's robustness against adverse initializations by minimizing the distances between 2D keypoints. This framework systematically incorporates the distinctive characteristics and inherent rationale of render-and-compare and matching-based approaches. This comprehensive consideration equips the framework to effectively address a broader range of intricate and challenging scenarios, including instances with substantial angular deviations, all while maintaining a high level of prediction accuracy. Experimental results demonstrate the superior precision and robustness of our proposed jointly optimized framework when evaluated on synthetic and complex real-world data in challenging scenarios.

我们提出了一种名为iComMa的方法，用于解决计算机视觉中的6D姿态估计问题。传统的姿态估计方法通常依赖于目标的CAD模型或需要针对特定物体类别进行特定的网络训练。一些现有方法通过采用神经辐射场（NeRF）的逆变换来解决无网格的6D姿态估计，旨在克服上述限制。然而，它仍然受到不良初始化的困扰。相比之下，我们将姿态估计建模为逆转3D高斯喷溅（3DGS）的问题，并结合了比较和匹配损失。具体来说，采用了渲染并比较策略来精确估计姿态。此外，设计了一个匹配模块，通过最小化2D关键点之间的距离，增强模型对不良初始化的鲁棒性。该框架系统性地结合了渲染并比较以及基于匹配方法的独特特征和内在逻辑。这种全面的考虑使该框架能够有效地解决更广泛的复杂和具有挑战性的场景，包括具有显著角度偏差的情况，同时保持高水平的预测准确性。实验结果表明，我们提出的联合优化框架在评估合成和复杂的现实世界数据的具有挑战性的场景时，展现出卓越的精度和鲁棒性。
