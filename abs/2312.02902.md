### HeadGaS: Real-Time Animatable Head Avatars via 3D Gaussian Splatting

3D head animation has seen major quality and runtime improvements over the last few years, particularly empowered by the advances in differentiable rendering and neural radiance fields. Real-time rendering is a highly desirable goal for real-world applications. We propose HeadGaS, the first model to use 3D Gaussian Splats (3DGS) for 3D head reconstruction and animation. In this paper we introduce a hybrid model that extends the explicit representation from 3DGS with a base of learnable latent features, which can be linearly blended with low-dimensional parameters from parametric head models to obtain expression-dependent final color and opacity values. We demonstrate that HeadGaS delivers state-of-the-art results in real-time inference frame rates, which surpasses baselines by up to ~2dB, while accelerating rendering speed by over x10.

三维头部动画在过去几年里取得了重大的质量和运行时间改进，特别是受益于可微分渲染和神经辐射场的进步。实时渲染是现实世界应用中非常渴望达到的目标。我们提出了 HeadGaS，这是第一个使用三维高斯分散（3DGS）进行三维头部重建和动画的模型。在本文中，我们介绍了一种混合模型，该模型将来自3DGS的显式表示与可学习的潜在特征基底相结合，这些特征可以与参数头部模型中的低维参数线性混合，以获得表情依赖的最终颜色和不透明度值。我们展示了 HeadGaS 在实时推理帧率方面提供了最先进的结果，其性能超过基准线高达约2dB，同时加速渲染速度超过10倍。
