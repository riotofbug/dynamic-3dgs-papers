### GaussianDreamer: Fast Generation from Text to 3D Gaussians by Bridging 2D and 3D Diffusion Models

In recent times, the generation of 3D assets from text prompts has shown impressive results. Both 2D and 3D diffusion models can help generate decent 3D objects based on prompts. 3D diffusion models have good 3D consistency, but their quality and generalization are limited as trainable 3D data is expensive and hard to obtain. 2D diffusion models enjoy strong abilities of generalization and fine generation, but 3D consistency is hard to guarantee. This paper attempts to bridge the power from the two types of diffusion models via the recent explicit and efficient 3D Gaussian splatting representation. A fast 3D object generation framework, named as GaussianDreamer, is proposed, where the 3D diffusion model provides priors for initialization and the 2D diffusion model enriches the geometry and appearance. Operations of noisy point growing and color perturbation are introduced to enhance the initialized Gaussians. Our GaussianDreamer can generate a high-quality 3D instance or 3D avatar within 15 minutes on one GPU, much faster than previous methods, while the generated instances can be directly rendered in real time.

近期，从文本提示生成3D资源取得了令人印象深刻的成果。2D和3D扩散模型都能帮助基于提示生成合理的3D对象。3D扩散模型具有良好的3D一致性，但由于可训练的3D数据昂贵且难以获得，其质量和泛化能力受限。2D扩散模型具有强大的泛化能力和细致的生成能力，但很难保证3D一致性。本文尝试通过最近的显式和高效3D高斯溅射表示，将这两种扩散模型的优势结合起来。我们提出了一种快速的3D对象生成框架，名为GaussianDreamer，其中3D扩散模型提供初始化的先验，而2D扩散模型丰富几何形状和外观。引入了噪点生长和颜色扰动操作来增强初始化的高斯分布。我们的GaussianDreamer可以在15分钟内在单个GPU上生成高质量的3D实例或3D头像，比之前的方法快得多，同时生成的实例可以直接实时渲染。
