### MoSca: Dynamic Gaussian Fusion from Casual Videos via 4D Motion Scaffolds

We introduce 4D Motion Scaffolds (MoSca), a neural information processing system designed to reconstruct and synthesize novel views of dynamic scenes from monocular videos captured casually in the wild. To address such a challenging and ill-posed inverse problem, we leverage prior knowledge from foundational vision models, lift the video data to a novel Motion Scaffold (MoSca) representation, which compactly and smoothly encodes the underlying motions / deformations. The scene geometry and appearance are then disentangled from the deformation field, and are encoded by globally fusing the Gaussians anchored onto the MoSca and optimized via Gaussian Splatting. Additionally, camera poses can be seamlessly initialized and refined during the dynamic rendering process, without the need for other pose estimation tools. Experiments demonstrate state-of-the-art performance on dynamic rendering benchmarks.

我们引入了 4D 运动支架（MoSca），这是一种神经信息处理系统，旨在从野外随意捕获的单目视频中重建和合成动态场景的新颖视图。为了解决这样一个具有挑战性和不适定的逆问题，我们利用了先验知识。基础视觉模型，将视频数据提升为一种新颖的运动支架（MoSca）表示，该表示紧凑且平滑地编码底层运动/变形，然后将场景几何和外观与变形场分离，并通过全局融合高斯进行编码。锚定到 MoSca 并通过高斯泼溅进行优化，在动态渲染过程中可以无缝初始化和细化相机姿势，无需其他姿势估计工具。实验证明了动态渲染基准上最先进的性能。
