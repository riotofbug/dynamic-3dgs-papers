### SplaTAM: Splat, Track & Map 3D Gaussians for Dense RGB-D SLAM

Dense simultaneous localization and mapping (SLAM) is pivotal for embodied scene understanding. Recent work has shown that 3D Gaussians enable high-quality reconstruction and real-time rendering of scenes using multiple posed cameras. In this light, we show for the first time that representing a scene by 3D Gaussians can enable dense SLAM using a single unposed monocular RGB-D camera. Our method, SplaTAM, addresses the limitations of prior radiance field-based representations, including fast rendering and optimization, the ability to determine if areas have been previously mapped, and structured map expansion by adding more Gaussians. We employ an online tracking and mapping pipeline while tailoring it to specifically use an underlying Gaussian representation and silhouette-guided optimization via differentiable rendering. Extensive experiments show that SplaTAM achieves up to 2X state-of-the-art performance in camera pose estimation, map construction, and novel-view synthesis, demonstrating its superiority over existing approaches, while allowing real-time rendering of a high-resolution dense 3D map.

密集型同时定位与地图构建（SLAM）对于具身场景理解至关重要。最近的工作显示，使用多个摆放的摄像头，3D高斯可以实现高质量重建和实时渲染场景。基于此，我们首次展示了用3D高斯表示一个场景，可以使用单个未摆放的单目RGB-D摄像头实现密集型SLAM。我们的方法，SplaTAM，解决了以前基于辐射场表示的限制，包括快速渲染和优化、判断区域是否已经被映射的能力，以及通过增加更多高斯来结构化地扩展地图。我们采用在线跟踪和映射流程，同时专门使用基于高斯的表示和通过可微分渲染的轮廓引导优化。广泛的实验表明，SplaTAM在相机姿态估计、地图构建和新视图合成方面实现了多达2倍的最先进性能，证明了其优于现有方法，同时允许对高分辨率密集3D地图进行实时渲染。
